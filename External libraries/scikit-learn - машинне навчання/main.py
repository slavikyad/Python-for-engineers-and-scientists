# -*- coding: utf-8 -*-
"""
# scikit-learn - машинне навчання
Бібліотека scikit-learn (http://scikit-learn.org) містить зручні для використання алгоритми машинного навчання з учителем (регресія, класифікація) і без учителя (кластеризація, зменшення розмірності), а також засоби для підготовки даних і вибору найкращої моделі даних. В прикладі за допомогою scikit-learn 0.19.1 розв'язується задача бінарної класифікації. Необхідно навчити класифікатор `RandomForestClassifier` розпізнавати класи *y* нових даних *x1*, *x2*. Для цього модель навчається на даних для навчання. Тестові дані використовуються для перевірки правильності роботи моделі на нових даних. Як видно, ця модель правильно визначає класи 100% тестових даних.

Але така однократна процедура не є надійною. Для надійної перевірки правильності в прикладі застосовується 3-х блокова перехресна перевірка моделі. Вона виконується шляхом поділу усіх даних на 3 частини (*xy1*, *xy2*, *xy3*). Далі для кожної частини функція `cross_val_score` виконує навчання моделі і розрахунок правильності на незадіяних для навчання частинах. Тепер середнє значення правильності - 85 %.

Окремою проблемою є визначення оптимальних значень параметрів моделі `n_estimators` і `max_depth`. Якщо кількість їх варіантів не велика, то можна виконати цю програму для різних значень і подивитись, у якому випадку правильність найвища.
"""
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

x=np.array([[0,1,1,2,2,3,2,3,1,3, 6,5,6,7,7,8,7,7,8,5],
            [1,1,3,1,2,2,3,4,4,8, 5,7,6,7,6,7,5,8,8,1]]) # дві ознаки класів
y=np.array( [0,0,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1,1,1] ) # мітки класів (бінарна класифікація)
x=x.T
plt.scatter(x[:,0], x[:,1], c=y, s=100) # візуалізація класів
plt.xlabel('x0'); plt.ylabel('x1'); plt.show()
print "Рисунок - Два класи даних"
# розбити дані (дані для навчання і тестові дані для перевірки)
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.5)

model=RandomForestClassifier(n_estimators=5, max_depth=3) # модель - випадковий ліс (n_estimators - кількість дерев, max_depth - глибина дерева)
model.fit(x_train, y_train) # виконати навчання
print y_test # фактичні тестові класи
print model.predict(x_test) # прогнозовані тестові класи
print model.score(x_test, y_test) # правильність класифікатора

# перехресна перевірка (удосконалення train_test_split + score)
from sklearn.model_selection import cross_val_score
s=cross_val_score(model, x, y, cv=3)
print s, s.mean() # правильність класифікатора на кожній ітерації і її середнє значення
    
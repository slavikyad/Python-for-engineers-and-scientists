# -*- coding: utf-8 -*-
"""
# scipy.optimize.fminbound - оптимізація функції однієї змінної з границями
В математиці оптимізацією називають задачу знаходження екстремуму (мінімуму або максимуму) функції *f(x)* в деякій області значень *x*. Оптимізація буває

* локальна - для пошуку локального екстремуму;
* глобальна - для пошуку глобального екстремуму.

Методи оптимізації поділяються на

* детерміновані;
* стохастичні;
* комбіновані.

За порядком похідної, що обчислюється, поділяються на

* прямі (обчислюються тільки значення функції);
* першого порядку (градієнтні);
* другого порядку.

Інтерфейсом для оптимізації функції однієї змінної різними методами є `minimize_scalar`. Розглянемо локальну оптимізацію скалярної функції (однієї змінної) $f(x)=sin(x)+cos(x^2)$ методом Брента.
"""
import numpy as np
from scipy.optimize import minimize_scalar, fminbound
def f(x): # функція однієї змінної (цільова функція)
    return np.sin(x)+np.cos(x**2)
res = minimize_scalar(f, bounds=(-3, 3), method='bounded') # знайти мінімум f(x) в заданих границях. Критерій пошуку - мінімум, допустима множина x від -3 до 3
print "argmin=",res.x

argmin = fminbound(f, -3, 3) # або так
print "argmin=", argmin
argmax = fminbound(lambda x: -f(x), -3, 3) # знайти максимум f(x) в заданих границях
print "argmax=", argmax

import matplotlib.pyplot as plt
x=np.linspace(-3,3,100)
plt.plot(x,f(x),'k') # графік
plt.scatter([argmin,argmax], [f(argmin),f(argmax)], linewidths=[3,3]) # локальні екстремуми
plt.xlabel('x');plt.ylabel('y');plt.grid();plt.show()
"""
Рисунок - Графік функції і знайдені локальні екстремуми
"""
